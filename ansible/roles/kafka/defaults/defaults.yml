# ansible_user: default_user # пользователь для коннекта по SSH
#ansible_ssh_pass: # пароль для "ansible_user"
tmp_dir: /tmp/installer # путь до временной директории на конечных серверах
wait_for_start: 120 # время (в секундах) на корректный старт приложения (падает с ошибкой при превышении)
check_correct_start: true # проверка корректности запуска приложения по наличию строки в логе
security: PLAINTEXT__ZK_PLAIN_NO_AUTH__KAFKA_PLAINTEXT_NO_AUTH # протокол безопасности
local_distribution_source: true # использовать дистрибутив, загруженный на localhost в каталог files
# возможные варианты:
#   PLAINTEXT__ZK_PLAIN_NO_AUTH__KAFKA_PLAINTEXT_NO_AUTH
#   PLAINTEXT__ZK_SASL_DIGEST_MD5_WITH_AUTH__KAFKA_PLAINTEXT_NO_AUTH
#   SASL_PLAINTEXT__ZK_SASL_DIGEST_MD5_WITH_AUTH__KAFKA_SASL_KERBEROS_WITH_AUTH
#   SASL_PLAINTEXT__ZK_SASL_KERBEROS_NO_AUTH__KAFKA_SASL_KERBEROS_WITH_AUTH
#   SASL_PLAINTEXT__ZK_SASL_KERBEROS_WITH_AUTH__KAFKA_SASL_KERBEROS_WITH_AUTH
#   SASL_PLAINTEXT__ZK_SASL_KERBEROS_WITH_AUTH__KAFKA_SASL_SSL_WITH_AUTH
#   SSL__ZK_PLAIN_NO_AUTH__KAFKA_SSL_NO_AUTH
#   SSL__ZK_PLAIN_NO_AUTH__KAFKA_SSL_WITH_AUTH
#   SSL__ZK_SASL_DIGEST_MD5_WITH_AUTH__KAFKA_SSL_WITH_AUTH

customJavaPath: false # абсолютный путь до используемой java ("customJavaPath"/bin/java) (или false для использования java из PATH)
ansible_no_log: false # отключить вывод паролей в лог/output
realm: "VM.MOS.CLOUD.SBRF.RU" # реалм ldap сервера

password_encoder_cli_path: password-encrypt-cli-1.3.jar # путь до утилиты для шифрования паролей

get_info:
  datadir: /home/mon99usr/dump # абсолютный путь на конечном сервере до папки с данными (необходимо пространство равное x2 пространства для логов )
  localDatadir: ./dump # абсолютный или относительный путь (от корня ansible) до папки в которую будем собирать данные

kafka_acls: []
#Examples
# kafka_acls:
#   - principal: ANONYMOUS # имя принципала
#     operations: ALL # разрешенные операции (Read,Write,Create,Delete,Alter,Describe,ClusterAction,AlterConfigs,DescribeConfigs,IdempotentWrite,All)
#     topics: "*" # используемые топики
#     cluster: true # добавление кластерной ACL (по умолчанию false)
#     groups: "*" # имена групп для подключения (обязательно для consumer)
#     command_configs: "./config/producer.properties"
#  - principal: CN=fqdn.foohost,OU=00CA,O=Savings Bank of the Russian Federation,C=RU # имя принципала (в случае с SSL)
#    operations: ALL # разрешенные операции
#    topics: "test2" # используемые топики
#    cluster: true # добавление кластерной ACL (по умолчанию false)
#    groups: "*" # имена групп для подключения (обязательно для consumer)
#  - principal: CN=ApacheKafka-Admins,OU=00CA,O=Savings Bank of the Russian Federation,C=RU
#    operations: ALL # разрешенные операции
#    topics: "*" # используемые топики
#    cluster: true # добавление кластерной ACL (по умолчанию false)
#    groups: "*" # имена групп для подключения (обязательно для consumer)
#  - principal: CN=ApacheKafka-RLM-Portal,OU=00CA,O=Savings Bank of the Russian Federation,C=RU
#    operations: ALL # разрешенные операции (Read,Write,Create,Delete,Alter,Describe,ClusterAction,AlterConfigs,DescribeConfigs,IdempotentWrite,All)
#    topics: "*" # используемые топики
#    cluster: true # добавление кластерной ACL (по умолчанию false)
#    groups: "*" # имена групп для подключения (обязательно для consumer)
#    #resource_pattern_type: PREFIXED # возможные значения <ANY|MATCH|LITERAL|PREFIXED>
#    #transactional_id: cep_transact # указание transactional-id

kafka_user: kafka
kafka_group: kafka

enabled_service: false
# default settings
kafka:
  distr: "kafka.zip" # путь до приложения относительно /files
  installdir: "/opt/Apache/kafka" # абсолютный путь на конечном сервере до приложения
  logdir: "/opt/Apache/kafka/logs" # абсолютный путь на конечном сервере до логов приложения
  datadir: "/KAFKADATA" # абсолютный путь на конечном сервере до данных приложения (через запятую, если путей несколько)
  #backup_installdir: /tmp/installer # если параметр задан, то делаем бэкап installdir в эту директорию. Не должно совпадать с installdir
  cleanLog: "true" # очистить путь до логов при установке
  cleanData: "true" # очистить путь до данных при установке
  xms: "256m" # начальный heap size
  xmx: "5G" # максимальный heap size
  port: "9093" # используемый порт
  jmxport: "7010" # порт для подключения по JMX
  jmx_security_enable: "true" # включение авторизации для JMX
  jmx_access_roles: # переменные для генерации доступов. Если переменная не определена, то текущие доступы не меняются
    - user: "myuser"
      access: "readonly"
      password: "mypassword"
  #id: 3 # уникальный broker.id для брокера в кластере (по умолчанию: порядковый номер хоста в inventory)
  #superUser: CN=00CA0000.KafkaCluster1,OU=00CA,O=SBRF,L=Moscow,C=RU # DN суперпользователя, иначе берется CN сертификата
  autoCreateTopics: "false" # автосоздание топиков
  trustStorePath: "ssl/kafka.jks" # путь от inventories/_стенд_/ до файла с trustStore (или абсолютный на сервере при needUploadJks: false)
  trustStorePassword: "SeCuRePaSsWorD2" # пароль от trustStore
  keyStorePath: "ssl/kafka.jks" # путь от inventories/_стенд_/ до файла с keyStore (или абсолютный на сервере при needUploadJks: false)
  keyStorePassword: "SeCuRePaSsWorD2" # пароль от keyStore
  keyPassword: "SeCuRePaSsWorD2" # пароль от ключа в хранилище
  #admin_rights: # список DN администраторов доступа
  #  - CN=00CA0000M.ControlPlane.ift.sbrf,OU=00CA,O=SBRF,L=Moscow,ST=Moscow,C=RU
  #iniChange: # изменить или добавить значение в файле формата ini/properties
  #  - fileName: /opt/Apache/kafka/etc/kafka/server.properties # полный путь до файла или относительно installdir
  #    changeList:
  #      - key: log.segment.bytes
  #        value: 1073741824
  #        section: Defaults # необязательное поле с именем [секции] для изменения
  #        state: absent # необязательное поле, при пустом value удаляет строчку с указанным key, при пустом section - удаляет секцию
  use_broker_not_zk: "true" # проводить создание/удаление topic/acl через брокер, а не через zookeeper (может работать не на всех версиях kafka!)
    # при SSL необходимо использовать переменные (можно передавать через --extra-vars):
    # admin_jks_file - путь до jks файла (локально, на сервере с ansible)
  # admin_jks_password - пароль от jks файла
  audit: # настройки аудита
    log: "true" # запись событий аудита в лог
    rest: "true" # запись событий аудита в rest endpoint
    trustStorePath: "ssl/kafka.jks" # путь от inventories/_стенд_/ до файла с trustStore
    trustStorePassword: "SeCuRePaSsWorD2" # пароль от trustStore
    keyStorePath: "ssl/kafka.jks" # путь от inventories/_стенд_/ до файла с keyStore
    keyStorePassword: "SeCuRePaSsWorD2" # пароль от keyStore
    keyPassword: "SeCuRePaSsWorD2" # пароль от ключа в хранилище
    url: "https://localhost:8084" # префикс url для отправки событий аудита
    metamodel: "v1/metamodel" # суффикс для метамодели
    event: "v1/event" # суффикс для событий
    system_id: "Synapse.ES Kafka Audit" # идентификатор событий аудита
  ssl_enabled_potocols: "TLSv1.2"
  ssl_client_auth: "required"
  ssl_endpoint_identification_algorithm: " "
  ssl_cipher_suites: "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"
  security_inter_broker_protocol: "SSL"
  config_providers: "decode"
  config_providers_decode_class: "ru.sbt.ss.kafka.DecryptionConfigProvider"
  config_providers_decode_param_security_encoding_class: "ru.sbt.ss.password.decoder.SimpleTextPasswordDecoder"
  config_providers_decode_param_security_encoding_salt: "ru.sbt.ss.password.salt.SbtSaltProvider"
  security_protocol: "SSL"
  ##
  offsets_retention_minutes: "43200"
  zookeeper_connection_timeout_ms: "30000"
  zookeeper_session_timeout_ms: "6000"
  max_incremental_fetch_session_cache_slots: "100000"
  log_roll_hours: "1"
  queued_max_requests: "1000"
  replica_fetch_max_bytes: "5242880"

# kafka_topics: []
## Examples
#kafka_topics:
#  replicationFactor: 1 # число брокеров Kafka для храненения топика (по умолчанию)
#  partitions: 10 # количетсво партиций (по умолчанию)
#  skipIfExists: true # пропускать создание, если топик уже существует
#  command_configs: "./config/producer.properties"
#  list:
#    - name: test1 # с дефолтными параметрами
#    - name: test2 # с указанием настроек
#      replicationFactor: 1
#      partitions: 5
#      configs: # изменение конфигурации на уровне топика (см. документацию)
#          - "cleanup.policy=compact"
#          - "max.message.bytes=10485760"
#


kafka_topics:
  replicationFactor: 1 # число брокеров Kafka для храненения топика (по умолчанию)
  partitions: 10 # количетсво партиций (по умолчанию)
  skipIfExists: true # пропускать создание, если топик уже существует
  # command_configs: "./config/producer.properties"
  list:
    - name: ufs-ul-sbercms-content-data
      replicationFactor: 1
      partitions: 2
    - name: ufs-sbercms-content-acknowledgement
      replicationFactor: 1
      partitions: 2  

rest:
  distr: confluent.zip  # путь до приложения относительно /files
  installdir: /opt/Apache/kafka-rest # абсолютный путь на конечном сервере до приложения ( ОСТОРОЖНО ПРИ УСТАНОВКЕ В ДИРЕКТОРИЮ С РАБОЧЕЙ KAFKA )
  logdir: /opt/Apache/kafka-rest/logs # абсолютный путь на конечном сервере до логов приложения
  cleanInstall: true # очистка installdir при установке ( ВЫКЛЮЧИТЬ ПРИ УСТАНОВКЕ В ДИРЕКТОРИЮ С РАБОЧЕЙ KAFKA )
  cleanLog: true # очистка logdir при установке
  xmx: 256m # максимальный heap size
  webport: 2088 # используемый порт
  jmxport: 7070 # порт для подключения по JMX
  id: kafka-rest-test-server # уникальный идентификатор инстанса Kafka Rest
  https:
    enable: false # включить использование https (иначе http)
    needUploadJks: true # необходимость загрузки хранилища на сервер
    trustStoreFilePath: ssl/https.jks # путь от корня ansible до файла с trustStore
    trustStorePassword: My+SFjwa0UeEWC4p0Dg5lnXkO0jnbE3r # пароль от trustStore (зашифрованный ./bin/password-encoder)
    keyStoreFilePath: ssl/https.jks # путь от корня ansible до файла с keyStore
    keyStorePassword: My+SFjwa0UeEWC4p0Dg5lnXkO0jnbE3r # пароль от keyStore (зашифрованный ./bin/password-encoder)
    keyPassword: My+SFjwa0UeEWC4p0Dg5lnXkO0jnbE3r # пароль от сертификата (зашифрованный ./bin/password-encoder)
  # используется при "security: SSL_*"
  needUploadJks: true # необходимость загрузки хранилища на сервер (для подключения к Kafka)
  trustStoreFilePath: ssl/broker.jks # путь от корня ansible до файла с trustStore
  trustStorePassword: My+SFjwa0UeEWC4p0Dg5lnXkO0jnbE3r # пароль от trustStore (зашифрованный ./bin/password-encoder)
  keyStoreFilePath: ssl/broker.jks # путь от корня ansible до файла с keyStore
  keyStorePassword: My+SFjwa0UeEWC4p0Dg5lnXkO0jnbE3r # пароль от keyStore (зашифрованный ./bin/password-encoder)
  keyPassword: My+SFjwa0UeEWC4p0Dg5lnXkO0jnbE3r # пароль от сертификата (зашифрованный ./bin/password-encoder)
  #iniChange: # изменить или добавить значение в файле формата ini/properties
  #  - fileName: etc/kafka-rest/kafka-rest.properties # полный путь до файла или относительно installdir
  #    changeList:
  #      - key: modification.cluster.deny
  #        value: "false"
  #        section: Defaults # необязательное поле с именем [секции] для изменения
  #        state: absent # необязательное поле, при пустом value удаляет строчку с указанным key, при пустом section - удаляет секцию

update_broker:
  distr: confluent.zip # путь до приложения относительно /files
  installdir: /opt/Apache/kafka/.tmp_confluent_411 # временная директория для новых бинарных файлов
  backup:
    enable: true # разрешить создание бекапа Kafka (файлов из директории kafka.installdir)
    path: /opt/Apache/kafka_backup.tar # путь до бекапа .tar (бекап создается только 1 раз)

zookeeper_user: zookeeper
zookeeper_group: zookeeper

enabled_service: false
# default settings
zookeeper:
  distr: "kafka.zip" # путь до приложения относительно /files
  installdir: "/opt/Apache/kafka" # абсолютный путь на конечном сервере до приложения
  logdir: "/opt/Apache/kafka/logs" # абсолютный путь на конечном сервере до логов приложения
  datadir: "/zookeeper" # абсолютный путь на конечном сервере до данных приложения
  #backup_installdir: /tmp/installer # если параметр задан, то делаем бэкап installdir в эту директорию. Не должно совпадать с installdir
  cleanLog: "true" # очистить путь до логов при установке
  cleanData: "true" # очистить путь до данных при установке
  xms: "128m" # начальный heap size
  xmx: "1G" # максимальный heap size
  port: "2181" # используемый порт
  jmxport: "7000" # порт для подключения по JMX
  jmx_security_enable: "true" # включение авторизации для JMX
  jmx_access_roleles: # переменные для генерации доступов. Если переменная не определена, то текущие доступы не меняются
    - user: "myuser"
      access: "readonly"
      password: "mypassword"
  #id: 3 # уникальный zookeeper id для quorum (по умолчанию: порядковый номер хоста в inventory)
  #superUser: CN=00CA0000.KafkaCluster1,OU=00CA,O=SBRF,L=Moscow,C=RU # DN суперпользователя, иначе берется CN сертификата
  quorumPorts: "2888:3888" # порты для quorum (первый - для лидера, второй - на всех хостах, включая лидера)
  trustStorePath: "ssl/zookeeper.jks" # путь от inventories/_стенд_/ до файла с trustStore
  trustStorePassword: "SeCuRePaSsWorD2" # пароль от trustStore
  keyStorePath: "ssl/zookeeper.jks " # путь от inventories/_стенд_/ до файла с keyStore
  keyStorePassword: "SeCuRePaSsWorD2" # пароль от keyStore

  #iniChange: # изменить или добавить значение в файле формата ini/properties
  #  - fileName: /opt/Apache/kafka/etc/kafka/zookeeper.properties # полный путь до файла или относительно installdir
  #    changeList:
  #      - key: tickTime
  #        value: 5000
  #        section: Defaults # необязательное поле с именем [секции] для изменения
  #        state: absent # необязательное поле, при пустом value удаляет строчку с указанным key, при пустом section - удаляет секцию
  config_providers: "decode"
  config_providers_decode_class: "ru.sbt.ss.kafka.DecryptionConfigProvider"
  security_encoding_class: "ru.sbt.ss.password.decoder.SimpleTextPasswordDecoder"
  security_encoding_salt: "ru.sbt.ss.password.salt.SbtSaltProvider"
  serverCnxnFactory:  "org.apache.zookeeper.server.NettyServerCnxnFactory"
  #SSL Quorum
  ssl_quorum_enabledProtocols: "TLSv1.2"
  sslQuorum: "true"
  ssl_quorum_ciphersuites: "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"
  ssl_quorum_hostnameVerification: "false"
  #SSL
  ssl_client_enable: "true"
  ssl_client_auth: "required"
  ssl_enabled_potocols: "TLSv1.2"
  ssl_endpoint_identification_algorithm: ""
  ssl_ciphersuites: "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"
  ssl_hostnameVerification: "false"
  ssl_client_portUnification: "false"
  #SSL AUTH
  ssl_clientAuth: "need"
  ssl_quorum_clientAuth: "need"
  ssl_enabledProtocols: "TLSv1.2"
  authProvider_x509: "org.apache.zookeeper.server.auth.X509AuthenticationProvider"
  ssl_authProvider: "x509"
  #PLAINT
  plaintext_client_portUnification: "true"
  #CLIENT
  zookeeper_ssl_endpoint_identification_algorithm: "false"
  clientCnxnSocket: "org.apache.zookeeper.ClientCnxnSocketNetty"


