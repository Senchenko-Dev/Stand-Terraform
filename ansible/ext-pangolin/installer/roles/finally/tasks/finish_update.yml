- name: Check args is correct
  assert:
    that: item.var not in ['null','']
    fail_msg: "ERROR: {{ item.name }} is empty"
    success_msg: "OK: {{ item.name }} is {{ item.var }}"
  loop:
    - { name: "_fnshupdt_pghome",           var: "{{ _fnshupdt_pghome }}" }
    - { name: "_fnshupdt_pgdata",           var: "{{ _fnshupdt_pgdata }}" }

- name: Enable backup_user connection in pg_hba
  block:

    - name: check that backup_user connection string is exists in hba
      shell: "cat {{ _fnshupdt_pgdata }}/pg_hba.conf"
      no_log: "{{ nolog }}"
      register: check_backup_user_exists

    - set_fact:
        result_backup_user_exists: "{{ check_backup_user_exists.stdout | \
                                    regex_search('^(\ {0,10}host|\ {0,10}-\ {0,10}host)([0-9a-z_A-Z\ \t0-9\/.,+])+\
                                    backup_user([0-9a-z_A-Z\ \t0-9\/.,+])+scram-sha-256.*$', multiline=True, ignorecase=True) }}"

    - name: enable backup_user connection in pg_hba
      include_role:
        name: common
        tasks_from: update_edit_pghba
      vars:
        the_insert_params: [ [ '^(.*)(hostssl) all.*127.0.0.1/32 cert(.*)$',
                               '        - host all backup_user 0.0.0.0/0 scram-sha-256' ] ]
        pghba_action: 'add'
      when: result_backup_user_exists | string | length <= 3

  become: true
  become_user: postgres     
  when: inventory_hostname != 'etcd'

- name: Enable backup_user in database
  include_role:
    name: common
    tasks_from: disable_backup_user
  vars:
    _dsblbckpusr_enable: true
    _dsblscrpits: false
    _python_postgresql_venv: "{{ python.postgresql_venv }}/bin/python3"
  when: SRC and inventory_hostname == 'master'

- name: Check encrypt space with actual user passwords
  shell: "{{ _fnshupdt_pghome }}/bin/pg_auth_config check"
  register: result
  until: result.stdout.find("FATAL") == -1
  retries: 5
  environment:
    PG_PLUGINS_PATH: "{{ _fnshupdt_pghome }}/lib"
  become: true
  become_user: postgres
  when: inventory_hostname != 'etcd'

- name: Wait when pangolin open port
  shell: '{{ _fnshupdt_pghome }}/bin/pg_isready -h {{ ansible_fqdn }} -p {{ ports.pg }}'
  register: result
  until: result.stdout.find("accepting connections") != -1
  retries: 60
  delay: 1
  become: true
  become_user: postgres
  when: inventory_hostname != 'etcd'

- name: Remove pg_receivewal daemon
  file:
    path: "{{ service_path_dir }}/pg_receivewal.service"
    state: absent
  become: true
  become_user: root
  when: inventory_hostname == 'master' and is_inner_full_backup and action_type == 'update_major'

- name: Wait cluster synchronization
  include_role:
    name: patroni
    tasks_from: update_wait_cluster_synchronization.yml
  vars:
    PGHOME: "{{ _fnshupdt_pghome }}"
  when: inventory_hostname == 'master' and is_patroni_exists

- name: Rename directory
  block:

    - name: stop Pangolin by pg_ctl
      block:

          - name: turn on pause mode
            include_role:
               name: patroni
               tasks_from: update_with_patronictl.yml
            vars:
               change_params: "pause: true"
            when: is_patroni_exists

          - name: stop Pangolin when patroni
            shell: "{{ _fnshupdt_pghome }}/bin/pg_ctl stop -D {{ PGDATA }}"
            become_user: postgres
            when: is_patroni_exists

          - name: stop Pangolin when not patroni
            service:
               name: postgresql
               state: stopped
            when: not is_patroni_exists

          - name: check that postgresql is not stopped
            shell: '{{ _fnshupdt_pghome }}/bin/pg_ctl status -D {{ PGDATA }}'
            register: result
            until: result.stdout.find("no server running") != -1
            retries: 6
            delay: 10
            failed_when: result.rc != 3
            become_user: postgres

    - name: rename PGDATA and PGARCLOGS
      block:

          - name: remove old PGHOME after update
            file:
              path: "{{ PGHOME_OLD }}"
              state: absent

          - name: remove old PGDATA and update old symlinks after update
            include_role:
              name: common
              tasks_from: rename_old_dirs_and_update_old_symlinks
            vars:
              _rodauos_old_path: "{{ [ pgdata_old_string.stdout, '/pgdata/11' ] | unique }}"
              _rodauos_new_path: "{{ pgdata_new_string.stdout }}"
              _rodauos_is_removed_old_dir: "{{ is_removed_old_pgdata }}"
              _rodauos_is_removed_new_dir: false
              _rodauos_is_rename_old_dir: true
              _rodauos_is_name_to_rename_old_dir: "{{ pgdata_old_string.stdout }}_pgdata_old_{{ ansible_date_time.date }}_{{ ansible_date_time.hour }}_{{ ansible_date_time.minute }}"
              _rodauos_new_symlink: "/pgdata/{{ pg_major_version }}"

          - name: remove old PGBACKUP and update old symlinks after update
            include_role:
              name: common
              tasks_from: rename_old_dirs_and_update_old_symlinks
            vars:
              _rodauos_old_path: [ "/{{ PGBACKUP.split('/').1 }}/04", "/{{ PGBACKUP.split('/').1 }}/11", "/{{ PGBACKUP.split('/').1 }}/05" ]
              _rodauos_new_path: "{{ PGBACKUP }}"
              _rodauos_is_removed_old_dir: false
              _rodauos_is_removed_new_dir: false
              _rodauos_is_rename_old_dir: true
              _rodauos_is_name_to_rename_old_dir: "/{{ PGBACKUP.split('/').1 }}/pgarclogs_old_{{ ansible_date_time.date }}_{{ ansible_date_time.hour }}_{{ ansible_date_time.minute }}"
              _rodauos_new_symlink: "/{{ PGBACKUP.split('/').1 }}/{{ pg_major_version }}"

          - name: define oid_tbls in replica
            set_fact:
               _mvusertbl_oid_tbls: "{{ hostvars['master']._mvusertbl_oid_tbls }}"
            when: inventory_hostname == 'replica'

          - name: update symbolic link of tablespaces
            file:
              src: "/{{ tablespace_location.split('/').1 }}/{{ old_dir.split('/').2 }}/{{ tablespace_location.split('/')[-1] }}/{{ item.spcname }}"
              dest: "/pgdata/{{ old_dir.split('/').2 }}/data/pg_tblspc/{{ item.oid }}"
              state: link
              force: yes
              owner: postgres
              group: postgres
            loop: "{{ _mvusertbl_oid_tbls.query_result }}"

    - name: replace data_tmp and pgarclogs_tmp in configure files
      block:

        - name: replace elem in the configuration file when not patroni
          replace:
             path: '{{ item.0 }}'
             regexp: "{{ item.1 }}"
             replace: "05"
          with_nested:
            - [ "/pgdata/{{ pg_major_version }}/data/postgresql.conf", "{{ service_path_dir }}/postgresql.service", "{{ PGUSERHOME }}/.bash_profile" ]
            - [ "data_tmp", "arclogs_tmp"]
          when: not is_patroni_exists

        - name: replace elem in the configuration file when patroni
          replace:
             path: '{{ item.0 }}'
             regexp: "{{ item.1 }}"
             replace: "05"
          with_nested:
            - [ "/pgdata/{{ pg_major_version }}/data/postgresql.conf", "{{ patroni_files.conf_dir }}/postgres.yml", "{{ service_path_dir }}/patroni.service", "{{ PGUSERHOME }}/.bash_profile" ]
            - [ "data_tmp", "arclogs_tmp"]
          when: is_patroni_exists

      become_user: root
      become: true

    - name: create new symlink for PGDATA
      block:

        - name: check /pgdata/{{ old_dir.split('/').2 }} exists
          stat:
            path: "/pgdata/{{ old_dir.split('/').2 }}"
          register: new_pgdata_exists

        - name: check symlink /pgdata/data exists
          stat:
            path: "/pgdata/data"
          register: new_link_pgdata_exists

        - name: create symlinks for {{ old_dir }}
          file:
            src: "/pgdata/{{ old_dir.split('/').2 }}"
            dest: "/pgdata/data"
            state: link
            force: yes
            owner: postgres
            group: postgres
          when: new_pgdata_exists.stat.exists and not new_link_pgdata_exists.stat.exists

    - name: start Pangolin by pg_ctl and turn on cron as service
      block:

        - name: start patroni
          block:

            - name: turn on pause mode
              include_role:
                name: patroni
                tasks_from: update_with_patronictl.yml
              vars:
                change_params: "pause: false"

            - name: send reload command to patroni
              include_role:
                name: patroni
                tasks_from: update_with_patronictl.yml
              vars:
                endpoint_name: reload
              run_once: true

            - name: restart master
              block:

                - name: restart new version Pangolin by patroni.service
                  systemd:
                    name: patroni
                    state: restarted
                    enabled: yes
                    daemon_reload: yes
                  become_user: root

                - name: loop wait for pgsql started
                  shell: '{{ _fnshupdt_pghome }}/bin/pg_isready -h 127.0.0.1 -p {{ ports.pg }}'
                  register: result
                  until: result.stdout.find("accepting connections") != -1
                  retries: 6
                  delay: 10
                  become_user: postgres

              when: inventory_hostname == 'master'

            - name: restart replica
              block:

                - name: restart new version Pangolin by patroni.service
                  systemd:
                    name: patroni
                    state: restarted
                    enabled: yes
                    daemon_reload: yes
                  become_user: root

                - name: loop wait for pgsql started
                  shell: '{{ _fnshupdt_pghome }}/bin/pg_isready -h 127.0.0.1 -p {{ ports.pg }}'
                  register: result
                  until: result.stdout.find("accepting connections") != -1
                  retries: 6
                  delay: 10
                  become_user: postgres

              when: inventory_hostname == 'replica'

          when: is_patroni_exists

        - name: start Pangolin
          systemd:
            name: postgresql
            state: started
            daemon_reload: yes
            enabled: yes
          when: not is_patroni_exists

        - name: loop wait for pgsql started
          shell: '{{ _fnshupdt_pghome }}/bin/pg_isready -h 127.0.0.1 -p {{ ports.pg }}'
          register: result
          until: result.stdout.find("accepting connections") != -1
          retries: 6
          delay: 10
          become_user: postgres
          when: not is_patroni_exists

  become: true
  when: inventory_hostname != 'etcd' and action_type == 'update_major'

- name: Update PGHOME symlinks
  block:

    - name: check {{ PGHOME }} exists
      stat:
        path: "{{ PGHOME }}"
      register: pghome_exists

    - name: check symlink /usr/pangolin exists
      stat:
        path: "/usr/pangolin"
      register: link_pghome_exists

    - name: check /usr/pgsql-se-{{ pg_current_version.split('.').0 }} exists
      stat:
        path: "/usr/pgsql-se-{{ pg_current_version.split('.').0 }}"
      register: other_link_pghome

    - name: create symlinks of PGHOME
      file:
        src: "{{ item.src }}"
        dest: "{{ item.dest }}"
        state: link
        force: yes
        owner: postgres
        group: postgres
      with_items:
        - { src: "{{ PGHOME }}",                       
            dest: "/usr/pangolin",                        
            condition: "pghome_exists.stat.exists" }
        - { src: "{{ PGHOME }}",                       
            dest: "/usr/pgsql-se-{{ pg_current_version.split('.').0 }}", 
            condition: "pghome_exists.stat.exists" }
      when: "{{ item.condition }}"

  become: true
  when: "inventory_hostname != 'etcd' \
         and action_type in ['update_major', 'update_minor']"

- name: Turn on cron as service
  systemd:
    state: restarted
    daemon_reload: yes
    name: crond
  become: true
  when: inventory_hostname != 'etcd'

- name: Create cron job pg_profile for major update
  block:

    - name: create extensions pg_cron if not install
      postgresql_ext:
        name: pg_cron
        schema: ext
        port: "{{ ports.pg }}"
        db: "{{ cron_db }}"
      when: cron_db_scheme is undefined

    - name: create cron job for pg_profile
      postgresql_query:
        query: "SELECT cron.schedule('{{ pg_profile.stats_periods }}', 'SELECT pgse_profile.take_sample()');"
        session_role: db_admin
        db: "{{ cron_db }}"
        port: "{{ ports.pg }}"
      register: result_cron_cfg

    - name: configure cron job for pg_profile
      postgresql_query:
        query: "UPDATE cron.job SET database='{{ _cfgpgprofile_install_db }}', username='profile_tuz' \
                  WHERE jobid='{{ result_cron_cfg.query_result[0].schedule }}';"
        db: "{{ cron_db }}"
        port: "{{ ports.pg }}"

  environment: "{{ db_connection_args }}"
  become: true
  become_user: postgres
  when: "pg_profile.is_enable \
         and action_type == 'update_major' \
         and inventory_hostname == 'master'"

- name: Check pending restart cluster and restart it if needed
  block:

    - name: get parameters from patroni service for standalone
      uri:
        url: "{{ protocol }}://{{ ansible_fqdn }}:{{ ports.patroni }}"
        return_content: yes
        status_code: 503
      register: patroni_parameters
      become_user: postgres

    - name: save patroni params from replica
      set_fact:
        patroni_parameters: "{{ patroni_parameters | string }}"

    - name: check restart condition from master node
      set_fact: 
        is_restart: "{{ ('pending_restart' in patroni_parameters)|bool }}"

    - name: to do checkpoint
      include_role:
        name: postgresql
        tasks_from: update_run_checkpoint.yml
      vars:
        _runcheckpoint_database_port: "{{ ports.pg }}"
        _runcheckpoint_ansible_python_interpreter: "{{ PYTHON_VENV_OLD }}/bin/python3"

    - name: send restart command to patroni
      include_role:
        name: patroni
        tasks_from: update_with_patronictl.yml
      vars:
        endpoint_name: restart

    - name: loop wait for pgsql started
      shell: '{{ _fnshupdt_pghome }}/bin/pg_isready -h 127.0.0.1 -p {{ ports.pg }}'
      register: result
      until: result.stdout.find("accepting connections") != -1
      retries: 6
      delay: 10
      become_user: postgres

  become: true
  when: inventory_hostname == 'replica'

- name: Remove old PGHOME after update
  file:
    path: "{{ PGHOME_OLD }}"
    state: absent
  become: true
  when: inventory_hostname != 'etcd' and action_type == 'update_minor'

- debug: msg="{{ update_error_types_breakpoint_msg }}"
  when: is_recovery_test_mode and finally_error_um01m and inventory_hostname == 'master'
- debug: msg="{{ update_error_types_breakpoint_msg }}"
  when: is_recovery_test_mode and finally_error_um01r and inventory_hostname == 'replica'

- name: Unset args
  set_fact: 
    _fnshupdt_pghome: 'null'
    _fnshupdt_pgdata: 'null'