- name: Minor update of Pangolin
  block:

    - name: turn on synchronous mode and wait cluster synchronoused, needed for switchover
      block:

        - name: set type of error for recovery
          set_fact:
            update_errors: "{{ update_errors|combine(data, recursive=True) }}"
            cacheable: yes
          vars:
            data:
              types:
                pg: 
                  minor_before_first_switchover: true

        - debug: msg="{{ update_error_types_breakpoint_msg }}"
          when: is_recovery_test_mode and postgresql_error_umin001m and inventory_hostname == 'master'

        - name: turn on synchronous mode and then switchover
          include_role:
            name: patroni
            tasks_from: update_run_switchover
          vars:
            current_database_port: "{{ ports.pg }}"
            _runswitchover_pghome: "{{ PGHOME_OLD }}"
            PGHOME: "{{ PGHOME_OLD }}"

      become_user: postgres
      when: "installation_type == 'cluster' \
             and inventory_hostname == 'master'"

    - name: set type of error for recovery
      set_fact:
        update_errors: "{{ update_errors|combine(data, recursive=True) }}"
        cacheable: yes
      vars:
        data:
          types:
            pg: 
              minor_before_first_switchover: false
              minor_before_bin_updated: true

    - name: gather packages info
      package_facts:
        manager: "auto"
      no_log: "{{ nolog }}"

    - name: set python interpretator
      set_fact:
        ansible_python_interpreter: '{{ python.postgresql_venv }}/bin/python3'

    - name: check database connect to Pangolin
      shell: '{{ PGHOME_OLD }}/bin/pg_isready -h 127.0.0.1 -p {{ ports.pg }}'
      register: result
      until: result.stdout.find("accepting connections") != -1
      retries: 6
      delay: 10
      become_user: postgres

    - name: copy package with new version Pangolin to remote hosts
      copy:
        src: "{{ local_distr_path }}/{{ postgresql_package_file }}"
        dest: "{{ REMOTE_TMP }}"

    - name: find package files in directory
      find:
        paths: "{{ REMOTE_TMP }}"
        use_regex: yes
        patterns:  '{{ postgresql_package_file }}'

    - name: ensure data and log dirs exists
      file:
        path: "{{ item.path }}"
        state: "{{ item.state }}"
        owner: postgres
        group: postgres
        mode: 0700
      with_items:
        - { path: '{{ PGUSERHOME }}/',              state: 'directory' }
        - { path: '{{ PGLOGS }}/',                  state: 'directory' }
        - { path: '{{ PGSSL }}',                    state: 'directory' }
        - { path: '/var/run/postgresql/',           state: 'directory' }
        - { path: '{{ PGHOME }}',                   state: 'directory' }
        - { path: '{{ PGETCDIR }}/',                state: 'directory' }

    - name: include role for run checkpoint
      include_tasks: update_run_checkpoint.yml
      vars:
        _runcheckpoint_database_port: "{{ ports.pg }}"

    # перейти в асинхронный режим, чтобы текущий мастер продолжил работать на "запись"
    #чтобы patroni не выполнял failover в момент выключения одного из участников кластера
    - name: turn off synchronous mode and turn on PAUSE mode
      include_role:
        name: patroni
        tasks_from: update_with_patronictl.yml
      vars:
        change_params: "{{ item }}"
        PGHOME: "{{ PGHOME_OLD }}"
      with_items:
        - "pause: true"
        - "synchronous_mode: false"
        - "synchronous_mode_strict: false"
      when: is_patroni_exists

    - name: write new exports and aliases to bash_profile and update sudoers
      include_role:
        name: common
        tasks_from: bash_profile
      vars:
        component_name: postgresql

    - name: export path for old patroni directory
      lineinfile:
        path: "{{ shell_profile_file }}"
        insertafter: EOF
        line: "export PATH=$PATH:{{ PYTHON_VENV_OLD }}/bin"
        state: present
      become_user: postgres
      when: is_patroni_exists

    - name: safety stop Pangolin
      block:

        - name: stop postgresql as daemon
          shell: "{{ PGHOME_OLD }}/bin/pg_ctl stop -D {{ PGDATA_OLD }}"
          become_user: postgres
          when: is_patroni_exists

        - name: stop old version Pangolin as service
          service:
            name: postgresql
            state: stopped
          when: not is_patroni_exists

        - name: check that postgresql is stopped
          shell: '{{ PGHOME_OLD }}/bin/pg_ctl status -D {{ PGDATA_OLD }}'
          register: result
          until: result.stdout.find("no server running") != -1
          retries: 6
          delay: 10
          failed_when: result.rc != 3
          become_user: postgres

    - name: safety update Pangolin files
      block:

        - name: set python interpretator
          set_fact:
            ansible_python_interpreter: '{{ python.global_bin_2 }}'

        - debug: msg="{{ update_error_types_breakpoint_msg }}"
          when: is_recovery_test_mode and postgresql_error_umin002m and inventory_hostname == 'master'
        - debug: msg="{{ update_error_types_breakpoint_msg }}"
          when: is_recovery_test_mode and postgresql_error_umin002r and inventory_hostname == 'replica'

        - name: update Pangolin by new package
          package:
            name: "{{ REMOTE_TMP }}/{{ postgresql_package_file }}"
            state: latest
          when: ansible_os_family == 'RedHat'

        - name: update Pangolin by new package
          shell: "apt-get install {{ REMOTE_TMP }}/{{ postgresql_package_file }}"
          when: ansible_os_family == 'Altlinux'

        - name: set type of error for recovery
          set_fact:
            update_errors: "{{ update_errors|combine(data, recursive=True) }}"
            cacheable: yes
          vars:
            data:
              types:
                pg:
                  minor_before_bin_updated: false
                  minor_before_first_db_started: true

        - name: сopy product version file
          copy:
            src: "{{ playbook_dir }}/files/version"
            dest: "{{ PGHOME }}/share/version"
            owner: postgres
            group: postgres
            mode: u=rw,g=r,o=r

        - name: сhange permissions postgresql python bin
          file:
            path: "{{ python.postgresql_venv }}/bin/"
            state: "directory"
            owner: postgres
            group: postgres
            mode: 0700
            recurse: yes

        - name: copy 3rdparty extensions
          import_tasks: copy_3rdparty_extensions.yml

        - name: copy utilities
          include_tasks: utilities.yml

        - name: copy documentation
          include_role:
            name: doc

        - name: copy timescaledb to PGHOME
          copy:
            src: "{{ item.src }}"
            dest: "{{ item.dest }}"
            owner: postgres
            group: postgres
            mode: 0700
            directory_mode: yes
          with_items:
            - { src: '{{ local_distr_path }}/timescaledb{{ PGHOME }}/lib/',             dest: '{{ PGHOME }}/lib' }
            - { src: '{{ local_distr_path }}/timescaledb{{ PGHOME }}/share/extension/', dest: '{{ PGHOME }}/share/extension' }

        - name: copy merged patroni config
          copy:
            src: "{% if patroni %}\
                       {{ merge_cfg.result_pgse_patroni }}\
                  {% else %}\
                       {{ merge_cfg.result_pgse }}\
                  {% endif %}/postgres.yml"
            dest: "{{ patroni_files.conf_dir }}/postgres.yml"
            owner: postgres
            group: postgres
            mode: 0600
            remote_src: yes
          when: is_patroni_exists

        - name: copy merged Pangolin configs
          copy:
            src: "{{ merge_cfg.result_pgse }}/{{ item }}"
            dest: "{{ PGDATA }}/{{ item }}"
            owner: postgres
            group: postgres
            mode: 0600
            remote_src: yes 
          with_items:
            - "postgresql.conf"
            - "pg_hba.conf"

        - name: set permission files protect
          import_tasks: set_permission_files_protect.yml

        - name: update postgresql.service if exists
          template:
            src: postgresql.service.j2
            dest: "{{ service_path_dir }}/postgresql.service"
          when: not is_patroni_exists

        - name: update patroni.service if exists
          template:
            src: "{{ playbook_dir }}/roles/patroni/templates/patroni.service.j2"
            dest: "{{ service_path_dir }}/patroni.service"
          when: is_patroni_exists

        - name: just force re-read systemd services
          systemd:
            daemon_reload: yes

        - name: restart patroni service
          systemd:
            name: patroni
            state: restarted
          when: is_patroni_exists

    - name: safaty start new version of pangolin
      block:

        - name: set type of error for recovery
          set_fact:
            update_errors: "{{ update_errors|combine(data, recursive=True) }}"
            cacheable: yes
          vars:
            data:
              types:
                pg: 
                  minor_before_first_db_started: false
                  minor_after_first_db_started: true

        # при снятии режима "пауза" патрони сам поднимет ПГ, в качестве своего дочернего процесса
        - name: if turn off PAUSE mode then started Pangolin
          include_role:
            name: patroni
            tasks_from: update_with_patronictl.yml
          vars:
            change_params: "pause: false"
          when: is_patroni_exists

        - name: start new version Pangolin as service
          systemd:
            name: postgresql
            state: started
            enabled: yes
            daemon_reload: yes
          when: not is_patroni_exists

        - name: send reload command to postgresql
          shell: "{{ PGHOME }}/bin/pg_ctl reload -D {{ PGDATA }}"
          become_user: postgres
          when: not is_patroni_exists

        - name: send reload command to patroni
          include_role:
            name: patroni
            tasks_from: update_with_patronictl
          vars:
            endpoint_name: reload
          when: is_patroni_exists

        - name: loop wait for pgsql started
          shell: '{{ PGHOME }}/bin/pg_isready -h 127.0.0.1 -p {{ ports.pg }}'
          register: result
          until: result.stdout.find("accepting connections") != -1
          retries: 6
          delay: 10
          become_user: postgres
        
        - debug: msg="{{ update_error_types_breakpoint_msg }}"
          when: is_recovery_test_mode and postgresql_error_umin003m and inventory_hostname == 'master'
        - debug: msg="{{ update_error_types_breakpoint_msg }}"
          when: is_recovery_test_mode and postgresql_error_umin003r and inventory_hostname == 'replica'

    - name: remove cron job
      cron:
        name: "a job for postgresql clean logs"
        state: absent
      become: true
      become_user: postgres
      ignore_errors: yes

    - name: setup deleting and compressing old logs
      template:
        src: postgresql_clean_logs.j2
        dest: "{{ global_scripts }}/postgresql_clean_logs"
        owner: postgres
        group: postgres
        mode: 0751
      become: true

    - name: create cron job
      cron:
        name: "a job for postgresql clean logs"
        special_time: daily
        job: "{{ global_scripts }}/postgresql_clean_logs"
      become: true
      become_user: postgres

    - name: turn on synchronous mode and wait cluster synchronous
      block:

        - name: set type of error for recovery
          set_fact:
            update_errors: "{{ update_errors|combine(data, recursive=True) }}"
            cacheable: yes
          vars:
            data:
              types:
                pg: 
                  minor_after_first_db_started: false
                  minor_before_second_switchover: true

        - name: turn on synchronous mode and then switchover
          include_role:
            name: patroni
            tasks_from: update_run_switchover
          vars:
            current_database_port: "{{ ports.pg }}"

        - debug: msg="{{ update_error_types_breakpoint_msg }}"
          when: is_recovery_test_mode and postgresql_error_umin004m and inventory_hostname == 'master'

      become_user: postgres
      when: installation_type == 'cluster' and inventory_hostname == 'master'

    # обновить данные раздела bootstrap, хранящиеся в etcd
    - name: update bootstrap into etcd
      block:

        - name: set type of error for recovery
          set_fact:
            update_errors: "{{ update_errors|combine(data, recursive=True) }}"
            cacheable: yes
          vars:
            data:
              types:
                pg: 
                  minor_before_second_switchover: false
                  minor_bootstrap: true
        
        - debug: msg="{{ update_error_types_breakpoint_msg }}"
          when: is_recovery_test_mode and postgresql_error_umin005m and inventory_hostname == 'master'

        - name: update bootstrap
          import_tasks: update_bootstrap.yml

      when: inventory_hostname == 'master' and etcd

    - debug: msg="{{ update_error_types_breakpoint_msg }}"
      when: is_recovery_test_mode and postgresql_error_umin006m and inventory_hostname == 'master'
    - debug: msg="{{ update_error_types_breakpoint_msg }}"
      when: is_recovery_test_mode and postgresql_error_umin006r and inventory_hostname == 'replica'

    - name: set type of error for recovery
      set_fact:
        update_errors: "{{ update_errors|combine(data, recursive=True) }}"
        cacheable: yes
      vars:
        data:
          types:
            pg:
              minor_after_first_db_started: false
              minor_before_second_switchover: false
              minor_bootstrap: false

  rescue:

    - name: replica updated with error
      set_fact:
        update_errors: "{{ update_errors|combine(data, recursive=True) }}"
        cacheable: yes
      vars:
        data:
          aggregate: true
          hosts:
            replica: true
          components:
            pg: true
      run_once: true
      when: inventory_hostname == 'replica'

    - name: master updated with error
      set_fact:
        update_errors: "{{ update_errors|combine(data, recursive=True) }}"
        cacheable: yes
      vars:
        data:
          aggregate: true
          hosts:
            master: true
          components:
            pg: true
      run_once: true
      when: inventory_hostname == 'master'

  always:

    - name: set python interpretator
      set_fact:
        ansible_python_interpreter: '{{ python.global_bin_2 }}'

  become: true
