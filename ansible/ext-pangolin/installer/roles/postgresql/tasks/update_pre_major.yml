- name: Major pre update of Pangolin
  block:

    - name: trigger revert check
      block:

        - name: touch trigger
          file:
            path: "{{ update_status_files.dir }}/.trigger_stop_update"
            state: touch
          become: true
          when: is_recovery_test_mode and trigger_stop06m

        - name: trigger stop updated
          include_role:
            name: common
            tasks_from: trigger_stop_update

      when: inventory_hostname == 'master'

    - name: gather packages info
      package_facts:
        manager: "auto"
      no_log: "{{ nolog }}"

    - name: set python interpretator
      set_fact:
        ansible_python_interpreter: '{{ python.postgresql_venv }}/bin/python3'

    - name: check database connect to Pangolin
      shell: '{{ PGHOME_OLD }}/bin/pg_isready -h 127.0.0.1 -p {{ ports.pg }}'
      register: result
      until: result.stdout.find("accepting connections") != -1
      retries: 6
      delay: 10
      become_user: postgres

    - name: get old Pangolin encoding
      postgresql_query:
        port: "{{ PGPORT_OLD }}"
        query: SHOW SERVER_ENCODING
      register: old_postgres_encoding
      environment: "{{ db_connection_args }}"
      become_user: postgres

    - name: save cron parameters
      block:

        - name: get database installed cron
          postgresql_query:
            query: SHOW cron.database_name;
            port: "{{ PGPORT_OLD }}"
          register: cron_db

        - name: save old parameter cron.database_name
          set_fact:
            cron_db: "{{ cron_db.query_result[0]['cron.database_name'] }}"

        - name: request pg_cron extension that installed in {{ cron_db }}
          postgresql_query:
            port: "{{ PGPORT_OLD }}"
            db: "{{ cron_db }}"
            query: "SELECT format('postgres.%1$s.%2$s',nspname,extname) extname FROM pg_catalog.pg_extension ex \
                      JOIN pg_namespace ns ON ex.extnamespace =ns.oid \
                    WHERE ex.extname='pg_cron';"
          register: _request_cron_db_scheme

        - name: installed ext pangolin
          set_fact:
            cron_db_scheme: "{{ _request_cron_db_scheme.query_result[0].extname.split('.').1 }}"
          when: _request_cron_db_scheme.query_result

      environment: "{{ db_connection_args }}"
      when: inventory_hostname == 'master'

    - name: save structure tablespace old version
      block:

        - name: get the oid of the tablespaces to move it
          postgresql_query:
            port: "{{ PGPORT_OLD }}"
            query: SELECT oid, spcname FROM pg_tablespace WHERE spcname not in ('pg_default', 'pg_global')
          register: oid_tablespace_old

        - name: get location of moving tablespaces
          postgresql_query:
            port: "{{ PGPORT_OLD }}"
            query: "SELECT pg_tablespace_location({{ item.oid }})"
          register: tablespace_old_path
          with_items: "{{ oid_tablespace_old.query_result }}"

        - name: save main dir tablespace old version
          set_fact:
            tablespace_old_path: "{{ tablespace_old_path.results[0].query_result[0].pg_tablespace_location.split('/')[:-1] | join('/') }}"

        - name: get structure tablespace old version
          find:
            paths: "{{ tablespace_old_path }}"
            recurse: yes
            file_type: directory
            depth: 2
          register: tablespace_structure_old

        - name: save list old structure
          set_fact:
            tablespace_structure_old: "{{ tablespace_structure_old.files | map(attribute='path') | list }}"

      environment:
        - PGHOST: "{{ ansible_fqdn }}"
        - PGSSLCERT: "{{ pg_certs_pwd.postgres_cert }}"
        - PGSSLKEY: "{{ pg_certs_pwd.postgres_key }}"
        - PGSSLROOTCERT: "{{ pg_certs_pwd.root_ca }}"
      become_user: postgres

    - name: copy package with new version PG SE to remote hosts
      copy:
        src: "{{ local_distr_path }}/{{ postgresql_package_file }}"
        dest: "{{ REMOTE_TMP }}"

    - name: find package files in directory
      find:
        paths: "{{ REMOTE_TMP }}"
        use_regex: yes
        patterns:  '{{ postgresql_package_file }}'

    - name: ensure data and log dirs exists
      file:
        path: "{{ item.path }}"
        state: "{{ item.state }}"
        owner: postgres
        group: postgres
        mode: 0700
      with_items:
        - { path: '{{ PGUSERHOME }}/',                          state: 'directory' }
        - { path: '{{ PGLOGS }}/',                              state: 'directory' }
        - { path: '{{ PGSSL }}',                                state: 'directory' }
        - { path: '/var/run/postgresql/',                       state: 'directory' }
        - { path: '{{ PGDATA }}',                               state: 'directory' }
        - { path: '{{ PGETCDIR }}/',                            state: 'directory' }
        - { path: '{{ PGHOME }}',                               state: 'directory' }

    - name: create {{ PGBACKUP }} dir if previous backup directory doesn't exist
      file:
        path: "{{ PGBACKUP }}"
        state: directory
        owner: postgres
        group: postgres
        mode: 0700
      become_user: root

    - name: set checkpoint DB
      include_tasks: update_run_checkpoint.yml
      vars:
        _runcheckpoint_database_port: "{{ ports.pg }}"

    - debug: msg="{{ update_error_types_breakpoint_msg }}"
      when: is_recovery_test_mode and postgresql_error_um001m and inventory_hostname == 'master'
    - debug: msg="{{ update_error_types_breakpoint_msg }}"
      when: is_recovery_test_mode and postgresql_error_um001r and inventory_hostname == 'replica'

    - name: install new Pangolin version
      block:

        - name: set python interpretator
          set_fact:
            ansible_python_interpreter: '{{ python.global_bin_2 }}'

        - name: update PG SE by new package
          shell: "rpm -ivh {{ REMOTE_TMP }}/{{ postgresql_package_file }}"

        - name: сopy product version file
          copy:
            src: "{{ playbook_dir }}/files/version"
            dest: "{{ PGHOME }}/share/version"
            owner: postgres
            group: postgres
            mode: u=rw,g=r,o=r

        - name: сhange permissions postgresql python bin
          file:
            path: "{{ python.postgresql_venv }}/bin/"
            state: "directory"
            owner: postgres
            group: postgres
            mode: 0700
            recurse: yes
          become_user: root

        - name: copy 3rdparty extensions
          import_tasks: copy_3rdparty_extensions.yml

        - name: copy utilities
          include_tasks: utilities.yml

        - name: copy documentation
          include_role:
            name: doc

        - name: copy timescaledb to PGHOME
          copy:
            src: "{{ item.src }}"
            dest: "{{ item.dest }}"
            owner: postgres
            group: postgres
            mode: 0700
            directory_mode: yes
          with_items:
            - { src: '{{ local_distr_path }}/timescaledb{{ PGHOME }}/lib/',             dest: '{{ PGHOME }}/lib' }
            - { src: '{{ local_distr_path }}/timescaledb{{ PGHOME }}/share/extension/', dest: '{{ PGHOME }}/share/extension' }

    - name: initializate new database
      block:

        - name: initializate standalone database
          shell: "{{ PGHOME }}/bin/pg_ctl -D {{ PGDATA }} initdb -o --data-checksums -o '-E={{ old_postgres_encoding.query_result[0].server_encoding }}'"
          environment:
            PG_PLUGINS_PATH: "{{ PGHOME }}/lib"
            LD_LIBRARY_PATH: "{{ PGHOME }}/lib"

        - name: initialize protection
          shell:
            cmd: "{{ PGHOME }}/bin/initprotection -D {{ PGDATA }}\ 
                -U {{ admin_protection_users.sec_admin_backup.user_name }},{{ admin_protection_users.sec_admin.user_name }}\ 
                -P '{{ admin_protection_users.sec_admin_backup.password }}','{{ admin_protection_users.sec_admin.password }}'"
          environment:
            PG_PLUGINS_PATH: "{{ PGHOME }}/lib"
          when: "admin_protection is defined and admin_protection"

        - name: rename default configs to base.conf
          shell: |
            mv "{{ PGDATA }}/postgresql.conf" "{{ PGDATA }}/postgresql.base.conf"
            mv "{{ PGDATA }}/pg_hba.conf" "{{ PGDATA }}/pg_hba.base.conf"

        - name: ensure data and log dirs exists
          file:
            path: "{{ PGDATA }}/pg_pp_cache/"
            state: directory
            owner: postgres
            group: postgres
            mode: 0700

        - debug: msg="{{ update_error_types_breakpoint_msg }}"
          when: is_recovery_test_mode and postgresql_error_um002m and inventory_hostname == 'master'

      become_user: postgres
      when: inventory_hostname == 'master'

    - name: fix new configs and service file
      block:

        - name: copy merged postgresql.conf and pg_hba.conf configs and prepare it
          block:

            - name: copy merged postgresql.conf and pg_hba.conf configs
              copy:
                src: "{{ merge_cfg.result_pgse }}/{{ item }}"
                dest: "{{ PGDATA }}/{{ item }}"
                owner: postgres
                group: postgres
                mode: 0600
                remote_src: yes 
              with_items:
                - "postgresql.conf"
                - "pg_hba.conf"

            - name: add enabled_extra_auth_methods with trust, turn off autovacuum and turn off cron job
              lineinfile:
                path: '{{ PGDATA }}/postgresql.conf'
                insertbefore: EOF
                firstmatch: yes
                line: "{{ item }}"
              with_items:
                - "autovacuum = 'off'"
                - "enabled_extra_auth_methods = 'trust'"
                - "cron.database_name = 'template1'"
                - "password_policy.allow_hashed_password = 'on'"

            - name: enable trust conn for upgrade {{ PGDATA }}/pg_hba.conf
              lineinfile:
                path: '{{ PGDATA }}/pg_hba.conf'
                insertbefore: BOF
                firstmatch: yes
                line: "local all postgres trust"

          become_user: postgres

        - name: remove depricated parameter from config
          lineinfile:
            path: "{{ PGDATA }}/postgresql.conf"
            regexp: "wal_keep_segments.*"
            state: absent
          become_user: postgres

    - name: block traffic and wait cluster synchronization
      block:

        - name: block traffic
          include_role:
            name: common
            tasks_from: block_traffic
          vars:
            block_traffic: true
            the_current_haproxy_port: "{{ ports.haproxy }}"
            the_current_pgbouncer_port: "{{ ports.pgbouncer }}"
            the_current_pg_port: "{{ ports.pg }}"

        - name: get current PGHOME
          set_fact:
            _updpremjr_pghome: "{{ PGHOME_OLD }}"

        - name: wait cluster synchronization
          include_role:
            name: patroni
            tasks_from: update_wait_cluster_synchronization.yml
          vars:
            PGHOME: "{{ _updpremjr_pghome }}"

      when: inventory_hostname == 'replica'

    - name: stop pg_receivewal daemon and show info
      block:

      - name: stop pg_receivewal daemon
        systemd:
          name: pg_receivewal
          state: stopped
        become_user: root

      - debug:
          msg: "{{ update_control_msgs.info.pg_receivewal_stop }}"

      when: inventory_hostname == 'master' and is_inner_full_backup and action_type == 'update_major'

    - debug: msg="{{ update_error_types_breakpoint_msg }}"
      when: is_recovery_test_mode and postgresql_error_um003m and inventory_hostname == 'master'
    - debug: msg="{{ update_error_types_breakpoint_msg }}"
      when: is_recovery_test_mode and postgresql_error_um003r and inventory_hostname == 'replica'

    - name: set python interpretator
      set_fact:
        ansible_python_interpreter: '{{ python.postgresql_venv }}/bin/python3'

    - name: turn off synchronous mode for continue update
      include_role:
        name: patroni
        tasks_from: update_with_patronictl.yml
      vars:
        change_params: "{{ item }}"
      with_items:
        - "synchronous_mode: false"
        - "synchronous_mode_strict: false"
      when: inventory_hostname == 'master' and installation_type == 'cluster'

    - name: make dump and calc dump checksums
      include_role:
        name: common
        tasks_from: make_dump_and_calc_dump_checksums.yml
      vars:
        _mdacdc_pghome: "{{ PGHOME_OLD }}"
        _mdacdc_pangolin_version: "{{ pg_current_version }}"
        _mdacdc_python_venv: "{{ python.postgresql_venv }}"
      when: "is_compare_checksums \
             and inventory_hostname == 'master' \
             and not is_recovery_test_mode"

    - name: prepare old pg_hba.conf and postgresql.conf
      block:

        - name: enable trust conn for upgrade {{ PGDATA_OLD }}/pg_hba.conf
          lineinfile:
            path: '{{ PGDATA_OLD }}/pg_hba.conf'
            insertbefore: BOF
            firstmatch: yes
            line: "local all postgres trust"

        - name: turn off vacuum, turn off synchronous_commit and turn off cron jobs of old version Pangolin
          lineinfile:
            path: '{{ PGDATA_OLD }}/postgresql.conf'
            insertbefore: EOF
            firstmatch: yes
            line: "{{ item }}"
          with_items:
            - "autovacuum = 'off'"
            - "synchronous_commit = 'off'"
            - "cron.database_name = 'template1'"

        - name: enable trust conn for upgrade by {{ PGDATA_OLD }}/postgresql.conf
          lineinfile:
            path: '{{ PGDATA_OLD }}/postgresql.conf'
            insertafter: EOF
            firstmatch: yes
            line: "enabled_extra_auth_methods = 'trust'"
          when: ( [ pg_current_version, '5.1.0' ] | compare_pg_se_versions )|int != 0

        - name: send reload command to postgresql
          shell: "{{ PGHOME_OLD }}/bin/pg_ctl reload -D {{ PGDATA_OLD }}"

        - name: check database connect to Pangolin
          shell: '{{ PGHOME_OLD }}/bin/pg_isready -h 127.0.0.1 -p {{ ports.pg }}'
          register: result
          until: result.stdout.find("accepting connections") != -1
          retries: 60
          delay: 1

      become_user: postgres

    - name: stop Pangolin
      block:

        - name: turn on pause mode after patroni nodes updated
          include_role:
            name: patroni
            tasks_from: update_with_patronictl.yml
          vars:
            change_params: "pause: true"

        - name: stop patroni
          service:
            name: patroni
            state: stopped
          when: is_patroni_exists and inventory_hostname == 'replica'

        - name: check exists pangolin service
          stat: path="{{ service_path_dir }}/postgresql.service"
          register: pg_service_exists

        - name: stop Pangolin
          block:

            - name: stop Pangolin
              service:
                name: postgresql
                state: stopped

            - name: check that postgresql is stopped
              shell: '{{ PGHOME_OLD }}/bin/pg_ctl status -D {{ PGDATA_OLD }}'
              register: result
              until: result.stdout.find("no server running") != -1
              retries: 6
              delay: 10
              ignore_errors: yes
              become_user: postgres

            - name: stop Pangolin
              shell: "{{ PGHOME_OLD }}/bin/pg_ctl stop -D {{ PGDATA_OLD }}"
              ignore_errors: yes
              become_user: postgres

          when: pg_service_exists.stat.exists

        - name: stop Pangolin
          shell: "{{ PGHOME_OLD }}/bin/pg_ctl stop -D {{ PGDATA_OLD }}"
          become_user: postgres
          when: not pg_service_exists.stat.exists

        - name: check that postgresql is stopped
          shell: '{{ PGHOME_OLD }}/bin/pg_ctl status -D {{ PGDATA_OLD }}'
          register: result
          until: result.stdout.find("no server running") != -1
          retries: 6
          delay: 10
          failed_when: result.rc != 3
          become_user: postgres

        - name: update postgresql.service after stopped old Pangolin service
          template:
            src: postgresql.service.j2
            dest: "{{ service_path_dir }}/postgresql.service"
          when: not is_patroni_exists

        - name: update patroni.service
          template:
            src: "{{ playbook_dir }}/roles/patroni/templates/patroni.service.j2"
            dest: "{{ service_path_dir }}/patroni.service"
          when: is_patroni_exists

        - name: just force re-read systemd services
          systemd:
            daemon_reload: yes

    - name: write new exports and aliases to bash_profile and update sudoers
      include_role:
        name: common
        tasks_from: bash_profile
      vars:
        component_name: postgresql

    - name: export path for old patroni directory
      lineinfile:
        path: "{{ shell_profile_file }}"
        insertafter: EOF
        line: "export PATH=$PATH:{{ python.patroni_venv }}/bin"
        state: present
      become_user: postgres

    - name: create {{ PGDATA.split('/')[:-1] | join('/') }} on replica for rsync
      file:
        path: "{{ PGDATA.split('/')[:-1] | join('/') }}"
        state: directory
        owner: postgres
        group: postgres
        mode: 0700
      when: inventory_hostname == 'replica'

    - name: change owner for {{ PGDATA }}
      file:
        path: /pgdata
        owner: "{{ ansible_user }}"
        recurse: true
        follow: no
      when: inventory_hostname == 'replica'

    - name: stop cron as service
      systemd:
        state: stopped
        name: crond

  rescue:

    - name: change owner for {{ PGDATA }}
      file:
        path: /pgdata
        owner: postgres
        recurse: true
        follow: no
      when: inventory_hostname == 'replica'

    - name: replica updated with error
      set_fact:
        update_errors: "{{ update_errors|combine(data, recursive=True) }}"
        cacheable: yes
      vars:
        data:
          aggregate: true
          hosts:
            replica: true
          components:
            pg: true
          types:
            pg: 
              major_pre: true
      run_once: true
      when: inventory_hostname == 'replica'

    - name: master updated with error
      set_fact:
        update_errors: "{{ update_errors|combine(data, recursive=True) }}"
        cacheable: yes
      vars:
        data:
          aggregate: true
          hosts:
            master: true
          components:
            pg: true
          types:
            pg: 
              major_pre: true
      run_once: true
      when: inventory_hostname == 'master'

  always:

    - name: set python interpretator
      set_fact:
        ansible_python_interpreter: '{{ python.global_bin_2 }}'

  become: true